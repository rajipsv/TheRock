# Strix AI/ML Integration - Architecture & Integration Overview

**Client Presentation Document**

## Executive Summary

This document outlines the architecture and integration of **AMD Strix (Strix Point gfx1150 and Strix Halo gfx1151)** AI/ML testing framework within TheRock repository. The solution provides comprehensive validation of Edge AI and Windows Copilot+ workloads on Strix integrated GPUs (iGPUs).

### Key Achievements
- âœ… **ROCm-accelerated AI/ML testing** on Strix iGPUs
- âœ… **Automated CI/CD pipeline** with GitHub Actions
- âœ… **Comprehensive test coverage**: VLM, VLA, ViT, CV, Optimization
- âœ… **Performance metrics capture** in JUnit XML format
- âœ… **Zero-download results** - All metrics visible in GitHub Actions logs

---

## 1. Architecture Overview

### 1.1 System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TheRock Repository                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            Strix AI/ML Test Framework                  â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚    â”‚
â”‚  â”‚  â”‚   VLM    â”‚  â”‚   VLA    â”‚  â”‚   ViT    â”‚  â”‚   CV   â”‚â”‚    â”‚
â”‚  â”‚  â”‚  Tests   â”‚  â”‚  Tests   â”‚  â”‚  Tests   â”‚  â”‚ Tests  â”‚â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚  Optimization    â”‚  â”‚    Quick Smoke Tests    â”‚   â”‚    â”‚
â”‚  â”‚  â”‚     Tests        â”‚  â”‚                         â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           GitHub Actions CI/CD Pipeline                â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  rocm/pytorch:latest Container                  â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - ROCm 6.x Runtime                             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - PyTorch with ROCm Backend                    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - AI/ML Libraries (transformers, ultralytics)  â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        Strix Hardware (Self-Hosted Runners)            â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  Strix Point     â”‚      â”‚   Strix Halo      â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  (gfx1150)       â”‚      â”‚   (gfx1151)       â”‚     â”‚    â”‚
â”‚  â”‚  â”‚  RDNA 3.5 iGPU   â”‚      â”‚   RDNA 3.5 iGPU   â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           Test Results & Metrics                       â”‚    â”‚
â”‚  â”‚  - JUnit XML with custom properties                    â”‚    â”‚
â”‚  â”‚  - Performance metrics (FPS, latency, memory)          â”‚    â”‚
â”‚  â”‚  - Displayed directly in GitHub Actions logs           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Component Architecture

#### Layer 1: Test Categories
| Category | Purpose | Models Tested |
|----------|---------|---------------|
| **VLM** (Vision Language Models) | Text-image understanding | CLIP |
| **VLA** (Vision Language Action) | Action prediction from vision | OWL-ViT, RT-style models |
| **ViT** (Vision Transformers) | Image classification | ViT-Base, DINOv2 |
| **CV** (Computer Vision) | Object detection | YOLOv8 |
| **Optimization** | FP16/INT8 quantization | Quantized models |
| **Quick Smoke** | Fast validation | Simple tests |

#### Layer 2: Container Infrastructure
```
rocm/pytorch:latest
â”œâ”€â”€ ROCm Runtime 6.x
â”œâ”€â”€ PyTorch 2.x+rocm6.x (GPU-enabled)
â”œâ”€â”€ torchvision
â”œâ”€â”€ transformers (Hugging Face)
â”œâ”€â”€ ultralytics (YOLO)
â”œâ”€â”€ opencv-python
â””â”€â”€ pytest framework
```

#### Layer 3: Hardware Layer
```
AMD Strix Platforms
â”œâ”€â”€ Strix Point (gfx1150)
â”‚   â”œâ”€â”€ RDNA 3.5 iGPU
â”‚   â”œâ”€â”€ Edge AI workloads
â”‚   â””â”€â”€ Windows Copilot+ scenarios
â”‚
â””â”€â”€ Strix Halo (gfx1151)
    â”œâ”€â”€ RDNA 3.5 iGPU (higher CU count)
    â”œâ”€â”€ Premium Edge AI
    â””â”€â”€ Enhanced Copilot+ performance
```

---

## 2. Integration Approach

### 2.1 Integration Points

#### A. Repository Integration
```
TheRock/
â”œâ”€â”€ tests/strix_ai/          # Strix-specific AI/ML tests
â”‚   â”œâ”€â”€ conftest.py          # Shared fixtures (GPU detection, images)
â”‚   â”œâ”€â”€ vlm/                 # Vision Language Model tests
â”‚   â”‚   â””â”€â”€ test_clip.py
â”‚   â”œâ”€â”€ vla/                 # Vision Language Action tests
â”‚   â”‚   â””â”€â”€ test_action_prediction.py
â”‚   â”œâ”€â”€ vit/                 # Vision Transformer tests
â”‚   â”‚   â””â”€â”€ test_vit_base.py
â”‚   â”œâ”€â”€ cv/                  # Computer Vision tests
â”‚   â”‚   â””â”€â”€ test_yolo.py
â”‚   â””â”€â”€ optimization/        # Optimization tests
â”‚       â””â”€â”€ test_quantization.py
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ strix_ai_tests.yml       # Main workflow (comprehensive)
â”‚   â””â”€â”€ strix_ai_quick_test.yml  # Quick validation workflow
â”‚
â””â”€â”€ docs/development/
    â”œâ”€â”€ STRIX_AI_ML_TEST_PLAN.md
    â”œâ”€â”€ STRIX_AI_QUICK_START.md
    â”œâ”€â”€ STRIX_TESTING_GUIDE.md
    â””â”€â”€ STRIX_CLIENT_ARCHITECTURE.md (this file)
```

#### B. CI/CD Integration

**Workflow Triggers:**
- âœ… **Automatic**: Push/PR to `users/*/strix_*`, `main`, `develop` branches
- âœ… **Path-filtered**: Only triggers when Strix test files change
- âœ… **Manual**: `workflow_dispatch` with custom parameters

**Workflow Features:**
```yaml
Triggers:
  - on: push (filtered by paths)
  - on: pull_request (filtered by paths)
  - on: workflow_dispatch (manual with inputs)

Container:
  - Image: rocm/pytorch:latest
  - GPU Access: --device /dev/kfd --device /dev/dri
  - IPC: host mode for shared memory

Runners:
  - linux-strix-halo-gpu-rocm (gfx1151)
  - linux-strix-point-gpu-rocm (gfx1150)
  - windows-strix-halo-gpu-rocm (Windows Copilot+)
```

### 2.2 Hardware Integration Strategy

#### Phase 1: Container-Based Testing âœ… **COMPLETED**
- Use official ROCm PyTorch containers
- GPU passthrough via Docker
- Minimal host dependencies
- **Advantage**: Reproducible, portable, fast setup

#### Phase 2: Direct Hardware Testing (Future)
- Native ROCm installation on runner host
- Direct GPU access without containers
- Windows-specific testing (DirectML, WinML)

#### Phase 3: Heterogeneous Testing (Future)
- Multi-GPU testing
- CPU+GPU hybrid workloads
- Power efficiency benchmarks

---

## 3. Technical Implementation

### 3.1 GPU Detection and Validation

**Automatic Detection:**
```python
# conftest.py - Shared fixture
@pytest.fixture(scope="session")
def strix_device():
    """Automatically detects and validates Strix GPU"""
    if not torch.cuda.is_available():
        pytest.skip("GPU not available")
    
    # Verify it's a Strix GPU
    amdgpu_family = os.getenv("AMDGPU_FAMILIES", "")
    if amdgpu_family not in ["gfx1150", "gfx1151"]:
        pytest.skip(f"Not a Strix device: {amdgpu_family}")
    
    return torch.device("cuda")
```

### 3.2 Metrics Capture

**JUnit XML with Custom Properties:**
```xml
<testcase name="test_vit_throughput" time="4.599">
  <properties>
    <property name="metric_throughput_fps" value="28.59"/>
    <property name="metric_latency_ms" value="34.98"/>
    <property name="metric_iterations" value="100"/>
    <property name="gpu_family" value="gfx1151"/>
  </properties>
</testcase>
```

**Test Implementation:**
```python
def test_vit_throughput(self, strix_device, record_property):
    # ... benchmark code ...
    
    # Capture metrics
    record_property("metric_throughput_fps", f"{fps:.2f}")
    record_property("metric_latency_ms", f"{latency_ms:.2f}")
    record_property("gpu_family", AMDGPU_FAMILIES)
```

### 3.3 Results Display

**Inline XML Display in GitHub Actions:**
```yaml
- name: ğŸ“Š Display Test Results XML
  run: |
    echo "::group::ğŸ“„ test-results-vit.xml"
    cat test-results-vit.xml
    echo "::endgroup::"
```

**Benefits:**
- âœ… No artifact download required
- âœ… Immediate visibility in logs
- âœ… Easy copy/paste for analysis
- âœ… Historical tracking via artifacts

---

## 4. Test Coverage Matrix

| Test Category | Models | Priority | Status | Metrics Captured |
|---------------|--------|----------|--------|------------------|
| **VLM** | CLIP | P0 | âœ… Implemented | Similarity scores, FPS, latency |
| **VLA** | OWL-ViT, Action Models | P1 | âœ… Implemented | Detection accuracy, latency |
| **ViT** | ViT-Base, DINOv2 | P0 | âœ… Implemented | FPS, latency, memory, confidence |
| **CV** | YOLOv8 | P0 | âœ… Implemented | Detection rate, FPS, accuracy |
| **Optimization** | FP16/INT8 | P1 | âœ… Implemented | Speedup, memory savings |
| **Quick Smoke** | Basic validation | P0 | âœ… Implemented | Pass/fail status |

---

## 5. Performance Metrics

### 5.1 Metrics Captured Per Test

#### Functional Tests:
- **Inference Time** - Single inference latency (ms)
- **Confidence Scores** - Model prediction confidence
- **Accuracy** - Correctness of predictions
- **Memory Usage** - Peak GPU memory (MB)

#### Benchmark Tests:
- **Throughput (FPS)** - Images/inferences per second
- **Latency (ms)** - Time per inference
- **Batch Performance** - Batch processing efficiency
- **Memory Efficiency** - FP16 vs FP32 memory usage

#### Optimization Tests:
- **Speedup** - FP16/INT8 vs FP32 speedup ratio
- **Memory Savings** - Memory reduction percentage
- **Model Size** - Quantized vs original model size

### 5.2 Example Results (Strix Halo gfx1151)

```xml
<!-- ViT Throughput Benchmark -->
<property name="metric_throughput_fps" value="28.59"/>
<property name="metric_latency_ms" value="34.98"/>
<property name="gpu_family" value="gfx1151"/>

<!-- ViT Memory Usage -->
<property name="metric_peak_memory_mb" value="415.29"/>

<!-- CLIP Performance -->
<property name="metric_throughput_fps" value="45.23"/>
<property name="metric_similarity_score_red" value="0.8523"/>
```

---

## 6. CI/CD Workflow Design

### 6.1 Workflow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Trigger Event                             â”‚
â”‚  (Push / PR / Manual)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Path Filter Check                               â”‚
â”‚  - tests/strix_ai/**                                         â”‚
â”‚  - .github/workflows/strix_ai*.yml                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Select Runner & Container                           â”‚
â”‚  Runner: linux-strix-halo-gpu-rocm                          â”‚
â”‚  Container: rocm/pytorch:latest                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Setup & Verification                              â”‚
â”‚  1. Checkout code                                            â”‚
â”‚  2. Verify ROCm/GPU (rocminfo)                              â”‚
â”‚  3. Install AI/ML dependencies                               â”‚
â”‚  4. Verify PyTorch GPU detection                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Run Test Categories (Parallel)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   VLM    â”‚  â”‚   VLA    â”‚  â”‚   ViT    â”‚  â”‚    CV    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚  â”‚   Opt    â”‚  â”‚  Quick   â”‚                                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Display Results & Archive                            â”‚
â”‚  1. Display XML in logs (::group::)                         â”‚
â”‚  2. Upload artifacts (30-day retention)                      â”‚
â”‚  3. Test summary                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Workflow Features

#### Smart Triggering:
- **Path-filtered** - Only runs when relevant files change
- **Branch-aware** - Supports feature branches, main, develop
- **Manual override** - Full control via workflow_dispatch

#### Environment Configuration:
```yaml
env:
  AMDGPU_FAMILIES: gfx1151  # GPU architecture
  TEST_CATEGORY: all         # Which tests to run
  PLATFORM: linux            # linux or windows
  PYTHONUNBUFFERED: 1        # Real-time output
```

#### Test Execution Strategy:
- **Sequential** by default - Clear, ordered results
- **Fail-safe** - `|| exit 0` prevents cascading failures
- **Environment isolation** - Each test gets AMDGPU_FAMILIES env var

---

## 7. Key Design Decisions

### 7.1 Container vs Native

**Decision: Use ROCm PyTorch Container** âœ…

**Rationale:**
| Aspect | Container | Native |
|--------|-----------|--------|
| Setup Time | Fast (~30s) | Slow (~5min) |
| Reproducibility | High | Medium |
| Maintenance | Low | High |
| Portability | High | Low |
| ROCm Version Control | Easy | Complex |

### 7.2 Test Organization

**Decision: Category-Based Structure** âœ…

**Rationale:**
- Clear separation of concerns
- Easy to run specific workloads
- Parallel execution friendly
- Matches AI/ML domain structure

### 7.3 Metrics Approach

**Decision: JUnit XML with Custom Properties** âœ…

**Rationale:**
- Standard format, wide tool support
- CI/CD integration built-in
- No external database needed
- Human-readable in logs
- Easy parsing for dashboards

### 7.4 Results Display

**Decision: Inline XML + Artifact Upload** âœ…

**Rationale:**
- Immediate visibility (no download)
- Historical tracking (artifacts)
- Easy debugging (click and read)
- Copy/paste friendly

---

## 8. Client Benefits

### 8.1 Technical Benefits

âœ… **Automated Validation**
- Every code change validated on real Strix hardware
- Catch regressions before production
- Continuous quality assurance

âœ… **Performance Tracking**
- Historical metrics for trend analysis
- Compare gfx1150 vs gfx1151 performance
- Identify optimization opportunities

âœ… **Comprehensive Coverage**
- All major AI/ML workloads tested
- Edge AI and Copilot+ scenarios validated
- Multiple model architectures verified

âœ… **Fast Feedback**
- Results in ~2-3 minutes (quick tests)
- XML visible immediately in logs
- No artifact download needed

### 8.2 Business Benefits

âœ… **Reduced Time-to-Market**
- Automated testing accelerates development
- Early bug detection reduces costs
- Parallel testing improves efficiency

âœ… **Quality Assurance**
- Consistent testing methodology
- Reproducible results
- Hardware-specific validation

âœ… **Scalability**
- Easy to add new test cases
- Support for multiple platforms (Linux/Windows)
- Extensible to new GPU architectures

âœ… **Transparency**
- All results visible in CI/CD logs
- Metrics tracked over time
- Clear pass/fail criteria

---

## 9. Future Enhancements

### 9.1 Short-term (Next 3 Months)

**Windows Testing:**
- DirectML integration
- WinML API validation
- Windows Copilot+ specific tests

**Extended Models:**
- Stable Diffusion on Strix
- Whisper (audio AI)
- LLaMA/Llama2 (LLMs)

**Performance Baselines:**
- Establish target FPS for each model
- Regression detection
- Automated alerts

### 9.2 Medium-term (3-6 Months)

**Dashboard Integration:**
- Web dashboard for metrics visualization
- Trend analysis over time
- Compare across GPU families

**Power Efficiency:**
- Power consumption metrics
- Performance-per-watt tracking
- Battery life impact (laptops)

**Multi-platform Matrix:**
- Linux + Windows parallel testing
- gfx1150 + gfx1151 comparison
- Automated cross-platform validation

### 9.3 Long-term (6-12 Months)

**End-to-End Scenarios:**
- Real Copilot+ workflows
- User-facing application testing
- Integration with OEM validation

**AI Model Zoo:**
- Pre-validated model repository
- Performance database
- Compatibility matrix

**Heterogeneous Computing:**
- CPU+GPU hybrid workloads
- NPU integration (future Strix)
- Multi-GPU scenarios

---

## 10. Getting Started

### 10.1 For Developers

**Run Tests Locally:**
```bash
# Ensure Strix GPU is available
rocminfo | grep gfx115

# Set environment
export AMDGPU_FAMILIES=gfx1151

# Run specific category
python3 -m pytest tests/strix_ai/vit/ -v -s

# Run all tests
python3 -m pytest tests/strix_ai/ -v -s -m "not slow"
```

**Trigger Workflow Manually:**
```bash
# Via GitHub UI: Actions â†’ Strix AI/ML Testing â†’ Run workflow
# Select: category=vit, platform=linux, test_type=quick
```

### 10.2 For Reviewers

**View Results:**
1. Navigate to GitHub Actions run
2. Click on "Strix AI Tests" job
3. Expand "ğŸ“Š Display Test Results XML" step
4. View XML with all metrics inline

**Download Artifacts (Optional):**
1. Scroll to bottom of workflow run
2. Download `strix-ai-test-results-linux-gfx1151-all.zip`
3. Extract and view XML files

---

## 11. Support & Documentation

### Reference Documents:
- **Test Plan**: `docs/development/STRIX_AI_ML_TEST_PLAN.md`
- **Quick Start**: `docs/development/STRIX_AI_QUICK_START.md`
- **Testing Guide**: `docs/development/STRIX_TESTING_GUIDE.md`
- **Workflow Usage**: `docs/development/STRIX_WORKFLOW_USAGE.md`

### Contact:
- **Repository**: `ROCm/TheRock`
- **Branch**: `users/rponnuru/strix_poc`
- **Workflows**: `.github/workflows/strix_ai_*.yml`

---

## 12. Conclusion

The Strix AI/ML integration provides a **production-ready, automated testing framework** for validating AMD Strix GPU performance across critical AI/ML workloads. With comprehensive metrics capture, inline result display, and CI/CD integration, the solution enables rapid iteration and quality assurance for Edge AI and Windows Copilot+ scenarios.

**Key Takeaways:**
- âœ… **Automated**: Tests run on every push/PR
- âœ… **Comprehensive**: VLM, VLA, ViT, CV, Optimization coverage
- âœ… **Performant**: Results in 2-3 minutes (quick), 15-20 minutes (full)
- âœ… **Transparent**: All metrics visible in logs, no download needed
- âœ… **Scalable**: Easy to extend with new models and platforms

---

**Document Version**: 1.0
**Last Updated**: December 12, 2025
**Status**: Production Ready

